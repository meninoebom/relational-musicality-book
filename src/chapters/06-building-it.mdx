---
title: "Building It"
subtitle: "What it means to take design knowledge from the forms and put it in code"
chapter: 6
---

I should tell you something about who's writing this.

I'm a DJ. I've been behind the decks for years — mostly house, mostly Chicago and Detroit lineage, mostly dark rooms where the point is not to be seen but to move. The opening scene of this book is from my life. That wasn't a thought experiment. That was a Tuesday.

I'm a capoeirista. I train in a lineage that takes the berimbau seriously as a governance instrument, not a prop. The second scene in this book — shifting the rhythm to change the game — that's something I've done dozens of times. It works. It works so reliably that it stops feeling remarkable, which is exactly when you should start paying attention to *why* it works.

I'm also a software engineer. React, Python, real-time systems, machine learning pipelines. I build things for a living. And this combination — practitioner of the forms, builder of tools — is why this book exists.

Because at some point, the question stopped being "what are these forms doing?" and became "can I build something that does it too?"

---

## What the System Wanted to Be

The obvious first attempt is a motion-triggered sampler. Wave your hand, hear a sound. Kick your foot, trigger a drum hit. Map some joints to some parameters, throw it on stage, call it "interactive."

I've seen these systems. They're impressive for about ninety seconds. Then you notice something: the relationship between mover and sound runs in one direction. You do something; the system reacts. The body is an input device, and the sound is an output. A fancy light switch.

That's not what happens in a roda. On a dance floor. In a jazz combo. In those systems, the sound shapes the movement shapes the sound. There's a loop. There's memory. There's something that develops over time. You establish common ground through repetition, and then variation becomes expressive *against* that ground. You can fall out of coherence and find your way back.

What these forms kept showing me was that the interesting thing isn't the trigger — it's the conversation. The system I needed to build had to treat the body as a conversational partner.

---

## RALF

I'm building a system called RALF — Relational Audio-visual Learning Framework. At the technical level, it's straightforward: motion capture feeds into gesture recognition, which sends control messages to a sound engine. Camera sees body. Software interprets movement. Sound responds.

But the design intent is specific, and it comes directly from the forms.

RALF is designed for **conversation**. The system should listen to movement, not just detect it. It should respond in ways that invite further movement. It should develop shared ground through repetition — the way a groove develops, the way a roda settles into a toque. And it should make variation meaningful within that ground, so that a subtle shift in dynamics or timing *matters* to the sound in the same way it matters to a good rhythm section.

There are layers to this.

The first layer is a single mover in dialogue with a sound environment. One body, responsive sound. This is where the core quality has to be right — does the mover feel *heard*? Not detected. Not measured. Heard. The way a good musician hears their bandmate. If this layer doesn't work, nothing built on top of it will.

The second layer is what I'm calling the composed space. Someone — maybe the mover, maybe someone else — has designed the gesture vocabulary, the mappings, the sound palette. They've made decisions about what movements will matter, what sounds will respond, what constraints will shape the interaction. This is the composer's conversation with the mover: here's the space I've built for you, discover what it affords.

The third layer is where it gets interesting. Multiple bodies in the same responsive environment. Each person's movement shapes the shared sound. And now something new becomes possible: *coordination between movers becomes audible*. When two people are in sync, the sound coheres. When they're in tension, the sound reflects that. When they're in counterpoint — doing different things that somehow fit — the sound reveals the relationship between them.

That's the layer where RALF connects to the forms. A roda, a dance floor, a jazz ensemble — these are all spaces where multiple participants create something together through a shared sonic medium. RALF is an attempt to build a technological version of that. A space where moving together sounds like something.

---

## What RALF Isn't

There's no score, no winning, no progress bar. There's coherence and expression and flow — but any movement produces response. You can't fail. You can only be more or less attuned.

It's not a performance capture system — this isn't about recording movement for later playback. The liveness is the point.

It's not a replacement for musicians or instruments. RALF is an instrument. One that requires the body and creates a new kind of musical voice. It's designed to join ensembles, not replace them.

And it's not the whole project. RALF is where the core technology gets proven — sensing, mapping, response, the feel of being in dialogue with a system. But the vision is bigger than one mover and one sound engine.

---

## Co-Regulated Music

Here's the bigger frame.

In any room where people share space, there's a collective state. How much attention is shared. Whether the energy is rising or dropping. Whether people are converging or fragmenting. Whether the tension is productive or corrosive. This state is real and consequential, and it's usually invisible. Someone might sense it intuitively — "the room feels off" — but there's no shared medium that makes it available to everyone at once.

Unless there's music.

A DJ reading a dance floor and adjusting the music to the room's energy is doing something precise: they're making the collective state audible, and they're shaping it through sound. They're in feedback with the room. The room moves; the DJ responds; the room responds to the response.

A berimbau player governing a roda is doing the same thing in a different context. So is a jazz rhythm section supporting a soloist. So is a lead singer adjusting the intensity of a call based on the energy of the chorus's response.

These are all instances of what I'm calling **co-regulated music**: sound environments that listen to the relational state of bodies in a space and shape that state in return. Sound as a responsive medium for coordination.

The practitioners of the forms have been doing this for generations. The DJ's art of reading a room. The rhythm section's support of a soloist. The berimbau's governance of the game. These are practiced, refined models of sonic co-regulation. They just haven't been formalized as transferable design knowledge.

That's what I'm working on. Not to replace the DJ or the berimbau player — you can't automate what they do, because what they do requires being a body in a room with other bodies. But to extend the principle. To build systems where the same dynamic — sound responds to bodies, bodies respond to sound, the collective state becomes available through a shared medium — can operate in contexts beyond the specific cultural forms where it developed.

Meetings. Classrooms. Rehabilitation clinics. Co-working spaces. Conflict mediation sessions. Gatherings where the purpose isn't artistic but the need for collective coherence is just as real.

The input can vary — cameras, motion sensors, acoustic detection, even something as simple as proximity. The output is always music. Something felt by the body, processed by the senses, available to everyone in the room simultaneously without anyone having to look at anything or read anything.

Music is the constant. It's the medium that the forms have proven works for coordination, and it's what makes co-regulated sound environments relational rather than informational. A dashboard tells you the room's state. Music puts you inside it.

---

## The Ethical Line

There's a version of this that I refuse to build.

A system that monitors bodies in a room and reports to management. A system that scores participation or measures engagement for someone's KPIs. A system that uses sensing as surveillance and optimization as control.

That's the bounded-self version of this technology — an external observer managing other selves. It would be easy to build. It would be a betrayal of everything the forms teach.

The forms don't surveil. The berimbau doesn't generate a report on player performance. The DJ doesn't send metrics to the club owner about how efficiently the floor converted passive listeners into active dancers. The sound is in the room, for the room. A shared medium, not an extraction pipeline.

Any system I build must hold this line. Measurement in service of flourishing, not control. Feedback that's felt, not filed. Sound that belongs to the people in the space, not to someone watching from outside.

As the forms teach: constraint is what makes freedom possible.

---

## Where This Sits

RALF is a research platform. Co-regulated music is a program of work. Neither is a finished product. What exists right now is a motion capture pipeline, a gesture recognition engine, and a set of mappings to sound — the simplest version of the first layer, one body in dialogue with a responsive environment.

But the architecture is designed to scale. The same pipeline — sense body state, recognize patterns, send control messages, shape sound — works for one body or twenty. What changes between a solo RALF session and a co-regulated meeting room isn't the technology. It's the theory layer: the model of what co-regulation means in each context, and the sound design that serves it.

The forms are the theory. They've been developing it for centuries. My job is translation — taking what the roda knows and making it available as design knowledge to someone building a conference room, a classroom, a clinic.

The way the arch traveled from Mesopotamia to Rome to the rest of the world — not by erasing its origin, but by understanding the principle clearly enough to build with it in new contexts.

That's the work. The next chapter is about what it could look like.
