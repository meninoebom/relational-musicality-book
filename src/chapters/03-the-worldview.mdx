---
title: "The Worldview Behind the Tools"
subtitle: "Why we build for sealed-off selves — and what it costs us"
chapter: 3
---

Open your phone. Count the apps. Every one of them assumes the same thing about you: that you are a single person, sitting alone, looking at a screen, managing your world.

Your email app manages your messages. Your calendar manages your time. Your fitness app manages your body. Your meditation app manages your attention. Your social media app manages your relationships — by which it means: your feed, your posts, your notifications.

Every one of these tools addresses a real need. And every one of them starts from the same assumption: *you* are a bounded unit — a self with an inside and an outside — and the job of technology is to help that unit operate more effectively on its environment. Or, increasingly, to help that unit optimize what's happening inside itself.

This isn't a conspiracy. It's a worldview. It's so pervasive it feels like common sense. But it's worth naming, because it determines what we build — and what we never think to build.

---

## The Buffered Self

The philosopher Charles Taylor has a useful term for this: the **buffered self**. A self that experiences itself as sealed off from the world, with a clear boundary between what's *me* and what's *not me*. My thoughts are mine. My feelings are mine. The world is out there; I am in here.

Taylor contrasts this with what he calls the **porous self** — the older, pre-modern experience of being a person, where the line between self and world was more permeable. Where you could be moved by forces that didn't originate inside your own head. Where the question "is this feeling mine or the room's?" wouldn't have sounded strange.

The buffered self has real advantages — autonomy, critical distance, the capacity for private reflection. But it has costs, and those costs are baked into the infrastructure of contemporary life.

When you design technology for a buffered self, you get interfaces for individuals. One user, one screen, one account. Even platforms that call themselves "social" are experienced through a personal feed — your timeline, your notifications, your algorithmic mirror. You get tools for control — the world is something to be managed, optimized, predicted. And you get a booming industry for the inside of the boundary — therapy apps, meditation apps, mood trackers, journaling prompts, biometric monitors — all aimed at optimizing the private interior of a sealed unit.

Two complementary industries emerge. Outer-directed technology: tools for managing the world. Inner-directed technology: tools for managing the self. Both address the same bounded entity. Both leave the boundary itself unquestioned.

---

## What Disappears

If you start from a sealed-off self, certain questions never get asked.

You don't ask: what if my state isn't fully mine? What if attention, presence, wellbeing aren't private possessions but *relational* — arising between people, in interaction, in shared time?

You don't build for: coordination as a capacity to be cultivated, not just a logistics problem to be solved. Trust that emerges from *doing things together*, not from contracts and verification systems. Intelligence that's distributed across bodies, not located in individual heads.

You don't notice that some of humanity's most sophisticated technologies for attention, coordination, and collective meaning-making operate on completely different assumptions about what a self is.

---

## A Different Starting Point

There's another way to understand what a person is. Philosophers call it **relational ontology** — which is a heavy phrase for a simple idea: selves aren't sealed containers that then enter into relationships. Selves are *constituted by* relationships. The boundary between inner and outer is real, but it's a membrane, not a wall. What happens between us is as fundamental as what happens inside us.

This runs through traditions across the world. The Southern African concept of *Ubuntu* — "I am because we are." The phenomenologist Merleau-Ponty's argument that bodies are always already intertwined with other bodies, perceiving and moving in shared space. Contemporary cognitive science, which increasingly recognizes that cognition is distributed, extended, enacted — not locked inside individual skulls.

And it runs through certain practices that never separated the inner from the outer in the first place.

---

## What Happens in the Age of AI

There's a reason this matters right now, and it isn't purely philosophical.

Generative AI is the logical endpoint of the buffered self's approach to intelligence. It takes the outputs of individual cognition — text, code, images, analysis — and produces them faster, cheaper, at scale. It does this by processing symbols. It does not need a body. It does not need a room. It does not need another person.

If intelligence is what happens inside a bounded unit processing information, then AI is better at it than we are. That's a clarification of what intelligence, in the buffered-self sense, actually is — and what it isn't.

What AI cannot do is be present. It cannot be moved by a room. It cannot feel the moment a dance floor locks in, or adjust a rhythm to govern a social interaction, or cry when a chord resolves at the right moment after a hard physical effort. It cannot coordinate with others through shared time. These aren't limitations that will be engineered away. They require being a body among bodies.

So AI, by doing the buffered self's job so efficiently, forces a question: if the outputs of individual cognition can be automated, what is it that humans actually do that matters?

The contemplative traditions have always had an answer: awareness, presence, the capacity to be transformed through relationship. The choreo-musical traditions have always had a demonstration: here, feel this, move with us, and you'll know what you are.

AI doesn't threaten these capacities. It clarifies them. But only if we're paying attention. The risk is that AI accelerates the buffered self's dominance. More output, faster, without integration. More answers without lived inquiry. More text on more screens, while the capacities that screens can't touch atrophy further.

---

## Agonistic Reappropriation

There's a tradition — a deep one, running through Afro-diasporic culture — of taking tools designed within one paradigm and bending them toward purposes that paradigm can't fully recognize.

Instruments made from whatever was available. Sound systems repurposed for collective entrainment — something they weren't designed for, but something they could be made to do. The DJ doesn't just "use" a sound system. The sound system becomes part of a social technology for coordinating hundreds of bodies in shared time.

This is closer to what I'd call **agonistic reappropriation**: taking tools built for the buffered self and repurposing them for relational, embodied, collective ends. Not rejecting the tools. Redirecting them.

That's the tradition I'm working in. Motion capture, machine learning, real-time audio synthesis — these are technologies built squarely within the bounded-self paradigm, designed for individual users managing external systems. But they can be bent. They can be made to listen to bodies. They can be made to respond to relationship. They can be made to create shared time instead of fragmenting it.

The question is: bent toward what? Repurposed for what?

For that, we need models. Working systems that already coordinate bodies, distribute intelligence, bridge inner and outer, and produce collective states that no individual controls.

We need the forms.

---

*Five of them. That's the next chapter.*
